{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Bidirectional, GRU, Dense, TimeDistributed\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, Reshape, MaxPool2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectrogram_feature(samples, sample_rate, stride_ms=10.0,\n",
    "                                window_ms=20.0, max_freq=None, eps=1e-14):\n",
    "    \"\"\"Compute the spectrograms for the input samples(waveforms).\n",
    "    More about spectrogram computation, please refer to:\n",
    "    https://en.wikipedia.org/wiki/Short-time_Fourier_transform.\n",
    "    \"\"\"\n",
    "    if max_freq is None:\n",
    "        max_freq = sample_rate / 2\n",
    "    if max_freq > sample_rate / 2:\n",
    "        raise ValueError(\"max_freq must not be greater than half of sample rate.\")\n",
    "\n",
    "    if stride_ms > window_ms:\n",
    "        raise ValueError(\"Stride size must not be greater than window size.\")\n",
    "\n",
    "    stride_size = int(0.001 * sample_rate * stride_ms)\n",
    "    window_size = int(0.001 * sample_rate * window_ms)\n",
    "\n",
    "    # Extract strided windows\n",
    "    truncate_size = (len(samples) - window_size) % stride_size\n",
    "    samples = samples[:len(samples) - truncate_size]\n",
    "    nshape = (window_size, (len(samples) - window_size) // stride_size + 1)\n",
    "    nstrides = (samples.strides[0], samples.strides[0] * stride_size)\n",
    "    windows = np.lib.stride_tricks.as_strided(\n",
    "      samples, shape=nshape, strides=nstrides)\n",
    "    assert np.all(\n",
    "      windows[:, 1] == samples[stride_size:(stride_size + window_size)])\n",
    "\n",
    "    # Window weighting, squared Fast Fourier Transform (fft), scaling\n",
    "    weighting = np.hanning(window_size)[:, None]\n",
    "    fft = np.fft.rfft(windows * weighting, axis=0)\n",
    "    fft = np.absolute(fft)\n",
    "    fft = fft**2\n",
    "    scale = np.sum(weighting**2) * sample_rate\n",
    "    fft[1:-1, :] *= (2.0 / scale)\n",
    "    fft[(0, -1), :] /= scale\n",
    "    # Prepare fft frequency list\n",
    "    freqs = float(sample_rate) / window_size * np.arange(fft.shape[0])\n",
    "\n",
    "    # Compute spectrogram feature\n",
    "    ind = np.where(freqs <= max_freq)[0][-1] + 1\n",
    "    specgram = np.log(fft[:ind, :] + eps)\n",
    "    return np.transpose(specgram, (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/toy_raw/174/168635/174-168635-0000.flac'\n",
    "\n",
    "au, sr = soundfile.read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 161)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = compute_spectrogram_feature(au, 16000, 10.0, 20.0)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss_lambda_func(y_true, y_pred):\n",
    "    \"\"\"Function for computing the CTC loss\"\"\"\n",
    "\n",
    "    if len(y_true.shape) > 2:\n",
    "        y_true = tf.squeeze(y_true)\n",
    "\n",
    "    input_length = tf.math.reduce_sum(y_pred, axis=-1, keepdims=False)\n",
    "    input_length = tf.math.reduce_sum(input_length, axis=-1, keepdims=True)\n",
    "    label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=True, dtype=\"int64\")\n",
    "\n",
    "    loss = K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def deep_speech(input_size, units, rnn_layers, is_bi, activation = 'relu', output_dim=29, learning_rate=3e-4):\n",
    "    \"\"\" Build a recurrent + convolutional network for speech \n",
    "    \"\"\"\n",
    "    \n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(input_size[0], input_size[1], 1))\n",
    "    x = input_data\n",
    "    \n",
    "    padding = (20, 5)\n",
    "    x = cnn = Conv2D(filters=32, \n",
    "                     kernel_size=(41,11), \n",
    "                     strides=(2,2), \n",
    "                     padding=[[0, 0], [padding[0], padding[0]], [padding[1], padding[1]], [0, 0]])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "#     padding = (10, 5)\n",
    "#     x = cnn = Conv2D(filters=32, \n",
    "#                      kernel_size=(21,11), \n",
    "#                      strides=(2,1), \n",
    "#                      padding=[[0, 0], [padding[0], padding[0]], [padding[1], padding[1]], [0, 0]])(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    \n",
    "    shape = x.get_shape()\n",
    "    x = Reshape((shape[1], shape[2] * shape[3]))(x)\n",
    "    \n",
    "    # Add a recurrent layer\n",
    "    if is_bi:\n",
    "        for i in range(rnn_layers):\n",
    "            # Add recurrent layer\n",
    "            x = Bidirectional(GRU(units, activation=activation,\n",
    "                return_sequences=True, name='rnn_{}'.format(i+1)))(x)\n",
    "            \n",
    "            #Add batch normalization \n",
    "            x = BatchNormalization()(x)\n",
    "    else:\n",
    "        for i in range(rnn_layers):\n",
    "            # Add recurrent layer\n",
    "            x = GRU(units, activation=activation,\n",
    "                return_sequences=True, name='rnn_{}'.format(i+1))(x)\n",
    "            \n",
    "            #Add batch normalization \n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    # Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(x)\n",
    "    \n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    \n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    \n",
    "    #compile model\n",
    "    optimizer = Adam(learning_rate=learning_rate) \n",
    "    model.compile(optimizer=optimizer, loss= ctc_loss_lambda_func)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, 1406, 40, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 703, 20, 32)       14464     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 703, 20, 32)       128       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 703, 640)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 703, 512)          1379328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 703, 512)          2048      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 703, 512)          1182720   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 703, 512)          2048      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 703, 512)          1182720   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 703, 512)          2048      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 703, 29)           14877     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 703, 29)           0         \n",
      "=================================================================\n",
      "Total params: 3,780,381\n",
      "Trainable params: 3,777,245\n",
      "Non-trainable params: 3,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import config\n",
    "\n",
    "data_detail = train.get_data_detail('toy_final')\n",
    "\n",
    "model = deep_speech(input_size = (data_detail['max_input_length'] , data_detail['num_features']), \n",
    "                                    units = config.model_architecture['units_rnn'], \n",
    "                                    rnn_layers = config.model_architecture['rnn_layers'], \n",
    "                                    is_bi = config.model_architecture['is_bi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
